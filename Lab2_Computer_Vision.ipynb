{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2-Computer-Vision.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JorgeHdzRiv/Program-neural-networks-with-TensorFlow/blob/main/Lab2_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Planteamiento del problema"
      ],
      "metadata": {
        "id": "LQFamJjDVUAO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sKswgmaMenc"
      },
      "source": [
        "Entrenarás una red neuronal para que reconozca artículos de ropa de un conjunto de datos común llamado Fashion MNIST. Contiene 70,000 prendas de ropa en 10 categorías diferentes. Cada ropa está en una imagen en escala de grises de 28 × 28.\n",
        "\n",
        "![alt text](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H41FYgtlHPjW"
      },
      "source": [
        "## Pasos iniciales\n",
        "\n",
        "Empezaremos importando TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3KzJyjv3rnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b507f23-bc8a-49db-a04d-e2a5a7a1e4f6"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teniendo etiquetas tales como:\n",
        "\n",
        "| Etiquetas   |      ***Descripcion ***     |  \n",
        "|----------|:-------------:|\n",
        "| 0 |  Camiseta/top | \n",
        "| 1 |  Pantalon   |   \n",
        "| 2 | Sueter|\n",
        "| 3 | Vestido |\n",
        "| 4 | Abrigo |\n",
        "| 5 | Sandalias |\n",
        "| 6 | Camisa|\n",
        "| 7 | Zapatos deportivos |\n",
        "| 8 | Bag |\n",
        "| 9 | Botas al tobillo |\n",
        "\n",
        "\n",
        "Los datos de Fashion MNIST están disponibles en la API de tf.keras.datasets. Cárgalo de la siguiente manera:"
      ],
      "metadata": {
        "id": "usyQZFSUV1N8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmxkHFpt31bM"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuoLQQBT4E-_"
      },
      "source": [
        "Si llamas a load_data en ese objeto, obtendrás dos conjuntos de dos listas: valores training y testing, que representan gráficos que muestran artículos de ropa y sus etiquetas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTdRgExe4TRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c1d88fb-57dc-4016-e6ba-1c6a382bac5f"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw395ROx4f5Q"
      },
      "source": [
        "¿Cómo son esos valores? Imprime una imagen de entrenamiento y una etiqueta de entrenamiento para ver. Puedes experimentar con diferentes índices en el array.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPc9d3gJ3jWF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b56888b0-bf8c-452e-9f9e-d25620fc950b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[0])\n",
        "print(training_labels[0])\n",
        "print(training_images[0])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
            "    0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
            "   54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
            "  144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
            "  107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
            "  216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
            "  223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
            "  235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
            "  180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
            "  169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
            "  198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
            "  232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
            "  222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
            "  211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
            "  224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
            "  255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
            "  188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
            "  168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
            "  239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
            "  199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
            "  195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
            "  210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
            "  182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cbrdH225_nH"
      },
      "source": [
        "Notarás que todos los valores son números enteros entre 0 y 255. Cuando se entrena una red neuronal, es más fácil tratar todos los valores entre 0 y 1, un proceso llamado normalización. Afortunadamente, Python proporciona una forma fácil de normalizar una lista como esta sin bucles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRH19pWs6ZDn"
      },
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "También es posible que desees ver 42, un inicio diferente al del índice 0.\n",
        "\n",
        "Ahora, es posible que se pregunte por qué hay dos conjuntos de datos: entrenamiento y pruebas.\n",
        "\n",
        "La idea es tener un conjunto de datos para el entrenamiento y otro conjunto de datos que el modelo aún no encuentre a fin de ver cómo clasificar los valores. Después de todo, cuando termines, tendrás que usar el modelo con datos que no había visto antes. Además, sin datos de prueba independientes, correrás el riesgo de que la red solo memorice los datos de entrenamiento sin generalizar sus conocimientos."
      ],
      "metadata": {
        "id": "KF0EBNHBZwbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diseñando el modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "rv668JcIZ4EP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIn7S9gf62ie"
      },
      "source": [
        "Ahora, diseña el modelo. Tendrás tres capas. Revíselas una por una y explore los diferentes tipos de capas y los parámetros que se utilizan para cada una."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mAyndG3kVlK"
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lUcWaiX7MFj"
      },
      "source": [
        "**Sequential**: define una secuencia de capas en la red neuronal.\n",
        "\n",
        "**Flatten**: toma un cuadrado y lo convierte en un vector unidimensional.\n",
        "\n",
        "**Dense**: agrega una capa de neuronas.\n",
        "\n",
        "Las funciones **Activation** indican a cada capa de neuronas qué hacer. Hay muchas opciones, pero úsalas por ahora:\n",
        "\n",
        "**Relu**: significa que, si X es mayor que 0, se muestra X; de lo contrario, se muestra 0. Solo pasa valores de 0 o mayores a la siguiente capa de la red.\n",
        "\n",
        "**Softmax**: toma un conjunto de valores y elige el más alto con eficacia. Por ejemplo, si el resultado de la última capa es [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], evita que debas ordenar por el valor más grande; muestra [0,0,0,0,1,0,0,0,0.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilando y entrenando el modelo\n"
      ],
      "metadata": {
        "id": "jRcmHHuzbtYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que el modelo está definido, lo siguiente que debes hacer es compilarlo. Para crear un modelo, primero debes compilarlo con una función **optimizer** y **loss** y, luego, entrenarlo con tus datos y etiquetas de entrenamiento. El objetivo es que el modelo descubra la relación entre los datos de entrenamiento y sus etiquetas de entrenamiento. Más adelante, deseas que el modelo vea datos que se asemejen a los de entrenamiento y, luego, haga una predicción sobre cómo deberían verse.\n",
        "\n",
        "Observa el uso de **metrics=** como parámetro, lo que permite que TensorFlow informe sobre la exactitud del entrenamiento verificando los resultados previstos con las respuestas conocidas (las etiquetas)."
      ],
      "metadata": {
        "id": "JsHTZ-rLbvjG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLMdl9aP8nQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67d83ca-ae64-4de3-8791-25ca2485b7ef"
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5002 - accuracy: 0.8249\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3790 - accuracy: 0.8628\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3366 - accuracy: 0.8780\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3129 - accuracy: 0.8857\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2985 - accuracy: 0.8892\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2827 - accuracy: 0.8943\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2664 - accuracy: 0.9000\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2594 - accuracy: 0.9045\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2471 - accuracy: 0.9080\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2400 - accuracy: 0.9098\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f688097d9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando el modelo se complete, verás un valor de exactitud al final del ciclo de entrenamiento final. Puede ser similar a 0.8926, como más arriba. Esto indica que tu red neuronal es aproximadamente un 89% precisa en la clasificación de los datos de entrenamiento. En otras palabras, descubrió una coincidencia de patrones entre la imagen y las etiquetas que funcionaron en el 89% de las veces. No es la mejor opción, pero no es nada mala, ya que solo se entrenó durante diez ciclos y se completó rápidamente."
      ],
      "metadata": {
        "id": "9L9i52bCe_K8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prueba del modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "xzPVhbnHfG2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Cuál sería el rendimiento del modelo con los datos que no vio? Por eso, tienes el conjunto de pruebas. Llamas a **model.evaluate** y pasas los dos conjuntos, que informa la pérdida de cada uno. Pruebe lo siguiente:"
      ],
      "metadata": {
        "id": "iufn7HazfKku"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzlqsEzX9s5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "600d4c6a-3936-4d04-aad1-6070d154e8be"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3510 - accuracy: 0.8748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35104039311408997, 0.8748000264167786]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ese ejemplo mostró una exactitud de 0 .8828, lo que significa que fue de aproximadamente un 88% de exactitud. (Es posible que tenga valores ligeramente diferentes).\n",
        "\n",
        "Como era de esperar, el modelo no es tan preciso con los datos desconocidos como con los datos con los que se entrenó. A medida que aprendas más sobre TensorFlow, encontrarás formas de mejorarlo."
      ],
      "metadata": {
        "id": "-VoCrEbvfW91"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htldZNWcIPSN"
      },
      "source": [
        "# Ejercicios de exploracion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rquQqIx4AaGR"
      },
      "source": [
        "###Ejercicio 1:\n",
        "Crea un conjunto de clasificaciones para cada una de las imágenes de prueba y, luego, imprime la primera entrada de las clasificaciones. El resultado después de que lo ejecutes es una lista de números. ¿Por qué crees que es eso y qué representan esas cifras?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyEIki0z_hAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7685b11b-5b15-4eb3-8284-49373a2b36d4"
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.5445329e-06 1.5285931e-07 3.6566462e-08 1.7524179e-08 4.4289430e-07\n",
            " 1.0213370e-02 2.7011177e-07 5.0167967e-02 1.7263141e-06 9.3961346e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdzqbQhRArzm"
      },
      "source": [
        "Intenta ejecutar **print(test_labels[0])** y obtendrás un 9. ¿Esto ayuda a entender por qué la lista se ve como lo hace? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnBGOrMiA1n5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54fafb55-e7ed-4628-8f47-490845d5e5b3"
      },
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El resultado del modelo es una lista de 10 números. Esos números son una probabilidad de que el valor que se clasifique sea la etiqueta correspondiente. Por ejemplo, el primer valor de la lista es la probabilidad de que la indumentaria sea de clase 0 y el siguiente es un 1. Tengan en cuenta que todas las probabilidades son muy bajas, excepto una. Además, debido a Softmax, todas las probabilidades de la lista suman 1.0.\n",
        "\n",
        "La lista y las etiquetas se basan en 0, por lo que el botín que tiene la etiqueta 9 significa que es la décima de las 10 clases. La lista en la que el décimo elemento tiene el valor más alto significa que la red neuronal predijo que el elemento que está clasificando es, probablemente, un tobillo."
      ],
      "metadata": {
        "id": "B3047QBXr9NF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgQSIfDSOWv6"
      },
      "source": [
        "##Ejercicio 2: \n",
        "Observa las capas del modelo. Experimenta con diferentes valores para la capa densa con 512 neuronas.\n",
        "\n",
        "¿Qué resultados se obtienen con la pérdida y el tiempo de entrenamiento? ¿Por qué crees que es así?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSZSwV5UObQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcafaaed-189e-4724-8396-31ec26e8317b"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "#Normalizando\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "#Creando el modelo\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "#Compilando el modelo\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "#Entrenando el modelo\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "#Evaluando\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4704\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3553\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3210\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2979\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2794\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3468\n",
            "[8.0993362e-07 8.5919032e-09 2.1354827e-08 1.4978015e-08 1.3370821e-07\n",
            " 4.8320014e-03 1.3666478e-06 1.3828821e-01 9.9569115e-07 8.5687637e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por ejemplo, si aumentas a 1,024 neuronas, debes hacer más cálculos, lo que ralentiza el proceso. Pero en este caso tienen un buen impacto, ya que el modelo es más preciso. Eso no quiere decir que siempre es mejor. Puedes cumplir con la ley de rendimiento que disminuye muy rápido.\n"
      ],
      "metadata": {
        "id": "dGT-NSYN3vVh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtWxK16hQxLN"
      },
      "source": [
        "##Ejercicio 3: \n",
        "\n",
        "¿Qué sucedería si quitaras la capa **Flatten()**? ¿Por qué crees que es así?\n",
        "\n",
        "Recibes un error sobre la forma de los datos. Los detalles del error pueden parecer poco precisos en este momento, pero refuerzan la regla general de que la primera capa de la red debería tener la misma forma que sus datos. En este momento, tus datos son de 28 x 28, y son imposibles de utilizar 28 capas de 28 neuronas, por lo que tiene más sentido compactar esos 28,28 en 784 x 1.\n",
        "\n",
        "En lugar de escribir todo el código, agrega la capa Flatten() al principio. Cuando los arrays se carguen después en el modelo, se acoplarán automáticamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExNxCwhcQ18S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "outputId": "9c33d471-fd91-45e8-e84f-ad1e35372cf1"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "\n",
        "#model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "#                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "#                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "\n",
        "#This version has the 'flatten' removed. Replace the above with this one to see the error.\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d4d3d65d595f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m               loss = 'sparse_categorical_crossentropy')\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1863, in sparse_categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5203, in sparse_categorical_crossentropy\n        labels=target, logits=output)\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(896, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqoCR-ieSGDg"
      },
      "source": [
        "##Ejercicio 4: \n",
        "\n",
        "Considera las capas finales (salida). ¿Por qué hay 10? ¿Qué sucedería si tuviera un importe diferente a 10?\n",
        "\n",
        "Intenta entrenar la red con 5. Verás un error en cuanto encuentre un valor inesperado. Otra regla general: la cantidad de neuronas en la última capa debe coincidir con la cantidad de clases que se están clasificando. En este caso, se trata de los dígitos del 0 al 9, por lo que hay 10 de ellos y, por lo tanto, deberías tener 10 neuronas en la capa final."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMckVntcSPvo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "75c0f496-dc13-4ce5-8768-778734fa1f8a"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "#model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "#                                   tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "#                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "Replace the above model definiton with this one to see the network with 5 output layers\n",
        "# And you'll see errors as a result!\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-aad9d96b607b>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    Replace the above model definiton with this one to see the network with 5 output layers\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0lF5MuvSuZF"
      },
      "source": [
        "##Ejercicio 5: \n",
        "\n",
        "Considera los efectos de las capas adicionales en la red. ¿Qué sucede si agregas otra capa entre la que tiene el 512 y la final con el 10?\n",
        "\n",
        "No hay un impacto significativo porque se trata de datos relativamente simples. Para datos mucho más complejos, a menudo se necesitan capas adicionales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1YPa6UhS8Es",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28632d37-76c3-4113-867f-21924e1a3dd2"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4682\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3530\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3194\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2940\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2775\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3486\n",
            "[1.1592122e-06 2.5983312e-08 1.9544345e-07 1.8723442e-07 5.1694098e-08\n",
            " 4.9793944e-03 8.9609347e-07 3.6076740e-03 8.4314689e-07 9.9140960e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bql9fyaNUSFy"
      },
      "source": [
        "#Ejercicio 6: \n",
        "\n",
        "Antes de entrenar, normalizó los datos, pasando de valores de 0 a 255, y de 0 a 1. ¿Cuál sería el impacto de quitarla? Este es el código completo que deseas probar. Ten en cuenta que se comentan las dos líneas que normalizan los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE3esj9BURQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7630ef0f-0e6f-4c3c-fc5f-f7434d39c314"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "#training_images = training_images/255.0\n",
        "#test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=30)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n",
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 3.2459\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6188\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5464\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5336\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5098\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4981\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4855\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4744\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4743\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4664\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4652\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4619\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4593\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4564\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4477\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4510\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4416\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4575\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4444\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4469\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4415\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4417\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4383\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4349\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4439\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4327\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4329\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4342\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4340\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4296\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.5904\n",
            "[2.1153144e-36 0.0000000e+00 0.0000000e+00 1.7011074e-32 4.3036390e-38\n",
            " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS3vVkOgCDGZ"
      },
      "source": [
        "#Ejercicio 7: \n",
        "\n",
        "Anteriormente, cuando se entrenaba para ciclos de entrenamiento adicionales, tenías un problema en el que la pérdida podía cambiar. Es posible que hayas esperado un poco para esperar a que se realizara la capacitación. Tal vez pensaste que sería beneficioso si pudieras detener la capacitación cuando alcances un valor deseado, como una precisión del 95%. Si alcanzas eso después de las 3 etapas, ¿por qué esperas a que terminen muchas más?\n",
        "\n",
        "Como cualquier otro programa, tienes devoluciones de llamada. Observa cómo funcionan:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDqNAqrpCNg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e8fc64-aab2-466b-eff0-882da04038b2"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.95):\n",
        "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4739 - accuracy: 0.8308\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3572 - accuracy: 0.8698\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3220 - accuracy: 0.8804\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2999 - accuracy: 0.8894\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2804 - accuracy: 0.8970\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f68761105d0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}